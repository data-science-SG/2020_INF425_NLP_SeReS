{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelo de detecção de sinais de depressão.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python388jvsc74a57bd076f535476cb180bb25368418d04a751d66ba878a98abd426d99537e4b422e099",
      "display_name": "Python 3.8.8 64-bit ('data_science': conda)",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSPh8aFQVWMt"
      },
      "source": [
        "# Modelo de detecção de sinais de depressão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CE6JN6AVVA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4f268a-fc42-4eb9-d6a0-2eeee6a24d5e"
      },
      "source": [
        "#Importes\n",
        "\n",
        "#Funções próprias\n",
        "import funcs\n",
        "from funcs.clean_text import clean_text\n",
        "from funcs.label_2_embedding import label2Embedding\n",
        "\n",
        "#Visualização de dados\n",
        "import pandas as pd \n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "#Pré-processamento\n",
        "!pip install emot\n",
        "import re\n",
        "from emot.emo_unicode import UNICODE_EMO, EMOTICONS\n",
        "\n",
        "#Manipulação de dados\n",
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "tknzr = TweetTokenizer()\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "#Para uso do GloVe\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "#Redes neurais\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\eduarda\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-1-780a2463368c>:10: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  pd.set_option('display.max_colwidth', -1)\n",
            "Requirement already satisfied: emot in c:\\users\\eduarda\\anaconda3\\envs\\data_science\\lib\\site-packages (2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\eduarda\\anaconda3\\envs\\data_science\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 8000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:109.)\n  return torch._C._cuda_getDeviceCount() > 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "CUDA_flag = torch.cuda.is_available() # a flag to check if CUDA is available for GPU use\n",
        "CUDA_flag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgv4VR7x09Tj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c18aca-8680-4abc-fe11-2cbc59bec2a7"
      },
      "source": [
        "np.random.seed(666)\n",
        "torch.manual_seed(666)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0xd012935990>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFEJMDjIkqRW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "5b6c0930-034b-4bad-a679-60d548569337"
      },
      "source": [
        "dataset = pd.read_csv('data\\Dataset_Depressao_24_11_2020.csv', index_col=0)\n",
        "dataset.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          usuario  \\\n",
              "0  lIlIIIlllllIII   \n",
              "1  rnnpgn           \n",
              "2  KMoraez          \n",
              "3  rammassss        \n",
              "4  fuckjxxnny_oh    \n",
              "\n",
              "                                                                                                                   texto  \\\n",
              "0  arrombada sem mae querendo cancelar um esquizofrênico\\r\\n\\r\\ndeu de internet por hoje https://t.co/I8SzMHuYV4           \n",
              "1  Não tem nada absolutamente mais SEM GRAÇA do que essa galera comentando em perfis esportivos com a foto do Casagrande   \n",
              "2  Abalada com toda a situação da minha vida                                                                               \n",
              "3  aí sempre fico feliz pelas conquistas dos meus amigos sabe.... sério                                                    \n",
              "4  respirando fundo pra nao socar a cara de ngm                                                                            \n",
              "\n",
              "   depressao  \\\n",
              "0  1           \n",
              "1  0           \n",
              "2  0           \n",
              "3  1           \n",
              "4  1           \n",
              "\n",
              "                                                                                                         texto_traduzido  \n",
              "0  broken into without a mother wanting to cancel a schizophrenic\\r\\n\\r\\ngave internet for today https://t.co/I8SzMHuYV4  \n",
              "1  There is nothing absolutely NO MORE FREE than this crowd commenting on sports profiles with Casagrande's photo         \n",
              "2  Shaken by the whole situation of my life                                                                               \n",
              "3  then I am always happy for the achievements of my friends you know .... seriously                                      \n",
              "4  taking a deep breath not to punch anyone in the face                                                                   "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>usuario</th>\n      <th>texto</th>\n      <th>depressao</th>\n      <th>texto_traduzido</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>lIlIIIlllllIII</td>\n      <td>arrombada sem mae querendo cancelar um esquizofrênico\\r\\n\\r\\ndeu de internet por hoje https://t.co/I8SzMHuYV4</td>\n      <td>1</td>\n      <td>broken into without a mother wanting to cancel a schizophrenic\\r\\n\\r\\ngave internet for today https://t.co/I8SzMHuYV4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>rnnpgn</td>\n      <td>Não tem nada absolutamente mais SEM GRAÇA do que essa galera comentando em perfis esportivos com a foto do Casagrande</td>\n      <td>0</td>\n      <td>There is nothing absolutely NO MORE FREE than this crowd commenting on sports profiles with Casagrande's photo</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KMoraez</td>\n      <td>Abalada com toda a situação da minha vida</td>\n      <td>0</td>\n      <td>Shaken by the whole situation of my life</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>rammassss</td>\n      <td>aí sempre fico feliz pelas conquistas dos meus amigos sabe.... sério</td>\n      <td>1</td>\n      <td>then I am always happy for the achievements of my friends you know .... seriously</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fuckjxxnny_oh</td>\n      <td>respirando fundo pra nao socar a cara de ngm</td>\n      <td>1</td>\n      <td>taking a deep breath not to punch anyone in the face</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uimir6i-c0z-",
        "outputId": "c8441468-a188-4ed1-e6e5-c5a6a30c046f"
      },
      "source": [
        "dataset['texto_traduzido'].dtype"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8GGQx92dLpf"
      },
      "source": [
        "dataset['texto_traduzido'] = dataset['texto_traduzido'].astype(str)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs-u-wU8mVT9"
      },
      "source": [
        "# Pré-processamento\n",
        "\n",
        "## \"Tradução\" de emojis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Cdco_idk3L7"
      },
      "source": [
        "def convert_emojis(text):\n",
        "    for emot in UNICODE_EMO:\n",
        "        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").split()))\n",
        "        text = text.replace(\":\",\" \")\n",
        "    return text"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSC8Z9QSmwyQ"
      },
      "source": [
        "dataset['documento_processado'] = dataset['texto_traduzido'].apply(lambda x: convert_emojis(x))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50y7FaOsW84e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "c35bc4bb-bce4-4d9a-9baa-80dc54b303ce"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          usuario  \\\n",
              "0  lIlIIIlllllIII   \n",
              "1  rnnpgn           \n",
              "2  KMoraez          \n",
              "3  rammassss        \n",
              "4  fuckjxxnny_oh    \n",
              "\n",
              "                                                                                                                   texto  \\\n",
              "0  arrombada sem mae querendo cancelar um esquizofrênico\\r\\n\\r\\ndeu de internet por hoje https://t.co/I8SzMHuYV4           \n",
              "1  Não tem nada absolutamente mais SEM GRAÇA do que essa galera comentando em perfis esportivos com a foto do Casagrande   \n",
              "2  Abalada com toda a situação da minha vida                                                                               \n",
              "3  aí sempre fico feliz pelas conquistas dos meus amigos sabe.... sério                                                    \n",
              "4  respirando fundo pra nao socar a cara de ngm                                                                            \n",
              "\n",
              "   depressao  \\\n",
              "0  1           \n",
              "1  0           \n",
              "2  0           \n",
              "3  1           \n",
              "4  1           \n",
              "\n",
              "                                                                                                         texto_traduzido  \\\n",
              "0  broken into without a mother wanting to cancel a schizophrenic\\r\\n\\r\\ngave internet for today https://t.co/I8SzMHuYV4   \n",
              "1  There is nothing absolutely NO MORE FREE than this crowd commenting on sports profiles with Casagrande's photo          \n",
              "2  Shaken by the whole situation of my life                                                                                \n",
              "3  then I am always happy for the achievements of my friends you know .... seriously                                       \n",
              "4  taking a deep breath not to punch anyone in the face                                                                    \n",
              "\n",
              "                                                                                                    documento_processado  \n",
              "0  broken into without a mother wanting to cancel a schizophrenic\\r\\n\\r\\ngave internet for today https //t.co/I8SzMHuYV4  \n",
              "1  There is nothing absolutely NO MORE FREE than this crowd commenting on sports profiles with Casagrande's photo         \n",
              "2  Shaken by the whole situation of my life                                                                               \n",
              "3  then I am always happy for the achievements of my friends you know .... seriously                                      \n",
              "4  taking a deep breath not to punch anyone in the face                                                                   "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>usuario</th>\n      <th>texto</th>\n      <th>depressao</th>\n      <th>texto_traduzido</th>\n      <th>documento_processado</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>lIlIIIlllllIII</td>\n      <td>arrombada sem mae querendo cancelar um esquizofrênico\\r\\n\\r\\ndeu de internet por hoje https://t.co/I8SzMHuYV4</td>\n      <td>1</td>\n      <td>broken into without a mother wanting to cancel a schizophrenic\\r\\n\\r\\ngave internet for today https://t.co/I8SzMHuYV4</td>\n      <td>broken into without a mother wanting to cancel a schizophrenic\\r\\n\\r\\ngave internet for today https //t.co/I8SzMHuYV4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>rnnpgn</td>\n      <td>Não tem nada absolutamente mais SEM GRAÇA do que essa galera comentando em perfis esportivos com a foto do Casagrande</td>\n      <td>0</td>\n      <td>There is nothing absolutely NO MORE FREE than this crowd commenting on sports profiles with Casagrande's photo</td>\n      <td>There is nothing absolutely NO MORE FREE than this crowd commenting on sports profiles with Casagrande's photo</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KMoraez</td>\n      <td>Abalada com toda a situação da minha vida</td>\n      <td>0</td>\n      <td>Shaken by the whole situation of my life</td>\n      <td>Shaken by the whole situation of my life</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>rammassss</td>\n      <td>aí sempre fico feliz pelas conquistas dos meus amigos sabe.... sério</td>\n      <td>1</td>\n      <td>then I am always happy for the achievements of my friends you know .... seriously</td>\n      <td>then I am always happy for the achievements of my friends you know .... seriously</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fuckjxxnny_oh</td>\n      <td>respirando fundo pra nao socar a cara de ngm</td>\n      <td>1</td>\n      <td>taking a deep breath not to punch anyone in the face</td>\n      <td>taking a deep breath not to punch anyone in the face</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aymLmDMjnGRD"
      },
      "source": [
        "##Limpeza de texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset[\"documento_processado\"] = [tknzr.tokenize(word) for word in dataset[\"documento_processado\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset[\"documento_processado\"] = [clean_text(sentence) for sentence in dataset[\"documento_processado\"]]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptFBT-dnnKl5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "9b8d136d-d718-4a9e-810d-6f2648c12dcd"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          usuario  \\\n",
              "0  lIlIIIlllllIII   \n",
              "1  rnnpgn           \n",
              "2  KMoraez          \n",
              "3  rammassss        \n",
              "4  fuckjxxnny_oh    \n",
              "\n",
              "                                                                                                                   texto  \\\n",
              "0  arrombada sem mae querendo cancelar um esquizofrênico\\r\\n\\r\\ndeu de internet por hoje https://t.co/I8SzMHuYV4           \n",
              "1  Não tem nada absolutamente mais SEM GRAÇA do que essa galera comentando em perfis esportivos com a foto do Casagrande   \n",
              "2  Abalada com toda a situação da minha vida                                                                               \n",
              "3  aí sempre fico feliz pelas conquistas dos meus amigos sabe.... sério                                                    \n",
              "4  respirando fundo pra nao socar a cara de ngm                                                                            \n",
              "\n",
              "   depressao  \\\n",
              "0  1           \n",
              "1  0           \n",
              "2  0           \n",
              "3  1           \n",
              "4  1           \n",
              "\n",
              "                                                                                                         texto_traduzido  \\\n",
              "0  broken into without a mother wanting to cancel a schizophrenic\\r\\n\\r\\ngave internet for today https://t.co/I8SzMHuYV4   \n",
              "1  There is nothing absolutely NO MORE FREE than this crowd commenting on sports profiles with Casagrande's photo          \n",
              "2  Shaken by the whole situation of my life                                                                                \n",
              "3  then I am always happy for the achievements of my friends you know .... seriously                                       \n",
              "4  taking a deep breath not to punch anyone in the face                                                                    \n",
              "\n",
              "                                                                                       documento_processado  \n",
              "0  [broken, without, mother, wanting, cancel, schizophrenic, gave, internet, today, https, t.co/i8szmhuyv4]  \n",
              "1  [nothing, absolutely, free, crowd, commenting, sports, profiles, casagrande's, photo]                     \n",
              "2  [shaken, whole, situation, life]                                                                          \n",
              "3  [always, happy, achievements, friends, know, ..., seriously]                                              \n",
              "4  [taking, deep, breath, punch, anyone, face]                                                               "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>usuario</th>\n      <th>texto</th>\n      <th>depressao</th>\n      <th>texto_traduzido</th>\n      <th>documento_processado</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>lIlIIIlllllIII</td>\n      <td>arrombada sem mae querendo cancelar um esquizofrênico\\r\\n\\r\\ndeu de internet por hoje https://t.co/I8SzMHuYV4</td>\n      <td>1</td>\n      <td>broken into without a mother wanting to cancel a schizophrenic\\r\\n\\r\\ngave internet for today https://t.co/I8SzMHuYV4</td>\n      <td>[broken, without, mother, wanting, cancel, schizophrenic, gave, internet, today, https, t.co/i8szmhuyv4]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>rnnpgn</td>\n      <td>Não tem nada absolutamente mais SEM GRAÇA do que essa galera comentando em perfis esportivos com a foto do Casagrande</td>\n      <td>0</td>\n      <td>There is nothing absolutely NO MORE FREE than this crowd commenting on sports profiles with Casagrande's photo</td>\n      <td>[nothing, absolutely, free, crowd, commenting, sports, profiles, casagrande's, photo]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KMoraez</td>\n      <td>Abalada com toda a situação da minha vida</td>\n      <td>0</td>\n      <td>Shaken by the whole situation of my life</td>\n      <td>[shaken, whole, situation, life]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>rammassss</td>\n      <td>aí sempre fico feliz pelas conquistas dos meus amigos sabe.... sério</td>\n      <td>1</td>\n      <td>then I am always happy for the achievements of my friends you know .... seriously</td>\n      <td>[always, happy, achievements, friends, know, ..., seriously]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fuckjxxnny_oh</td>\n      <td>respirando fundo pra nao socar a cara de ngm</td>\n      <td>1</td>\n      <td>taking a deep breath not to punch anyone in the face</td>\n      <td>[taking, deep, breath, punch, anyone, face]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtyZsPu3pJyW"
      },
      "source": [
        "## Codificando o texto para o nosso modelo\n",
        "Agora iremos fazer isso utilizando o GloVe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\eduarda\\\\Documents\\\\Workspace\\\\project\\\\2020_INF425_NLP_SeReS\\\\eda'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "cwd = os.getcwd()\n",
        "cwd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBUpGIATXikD"
      },
      "source": [
        "num_dims = 50\n",
        "\n",
        "glove_file = datapath(cwd+f'/data/glove.6B.{num_dims}d.txt')\n",
        "tmp_file   = get_tmpfile(cwd+f\"/data/glove.6B.{num_dims}d_word2vec.txt\")\n",
        "_          = glove2word2vec(glove_file, tmp_file)\n",
        "\n",
        "filename_txt = cwd+f\"/data/glove.6B.{num_dims}d_word2vec.txt\"\n",
        "modelo = KeyedVectors.load_word2vec_format(filename_txt)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_len = 280        # comprimento máximo da mensagem (em número de palavras)\n",
        "encoded_docs = []    # inicializa a lista de documentos codificados\n",
        "\n",
        "for sentence in dataset['documento_processado']: # para cada token\n",
        "  encoded_d = [label2Embedding(t, modelo) for t in sentence]\n",
        "  encoded_d = [vec.tolist() for vec in encoded_d if vec is not None]\n",
        "\n",
        "  # adiciona o padding, se necessário\n",
        "  padding_word_vecs = [np.zeros(num_dims).tolist()]*max(0, max_len-len(encoded_d)) \n",
        "  encoded_d = padding_word_vecs + encoded_d\n",
        "  \n",
        "  # trunca o documento e salva na lista de documentos codificados\n",
        "  encoded_docs.append(encoded_d[:max_len]) \n",
        "\n",
        "\n",
        "encoded_docs_arrays = [np.vstack(sentence) for sentence in encoded_docs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, numpy.ndarray, (280, 50))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "type(encoded_docs_arrays), type(encoded_docs_arrays[0]), encoded_docs_arrays[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
              "       ...,\n",
              "       [ 5.71210027e-01, -2.34229997e-01,  1.50670004e+00, ...,\n",
              "        -7.17770010e-02,  4.30299997e-01,  1.89400002e-01],\n",
              "       [ 2.77510000e-04,  4.26730007e-01, -8.29380006e-02, ...,\n",
              "         3.96149993e-01,  1.88570004e-02,  1.75359994e-01],\n",
              "       [ 1.26170003e+00,  2.66339988e-01,  4.76870000e-01, ...,\n",
              "         3.15109998e-01,  6.34980023e-01, -6.56949997e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "dataset['documento_processado'] = pd.Series(encoded_docs_arrays)\n",
        "dataset['documento_processado'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1411,), (280, 50), dtype('float64'))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "dataset['documento_processado'].shape, dataset['documento_processado'][0].shape, dataset['documento_processado'][0].dtype"
      ]
    },
    {
      "source": [
        "## Usando o modelo de classificação de emoções"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from funcs.model_class import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "Model = torch.load(cwd+'/../models/emotions_classifier_LSTM.pth', map_location=torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "moodClassifierWithLasersOnSteroids(\n",
              "  (embedding): Sequential(\n",
              "    (0): LSTM(100, 50, batch_first=True)\n",
              "  )\n",
              "  (ann): Sequential(\n",
              "    (0): Linear(in_features=50, out_features=50, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=50, out_features=6, bias=True)\n",
              "  )\n",
              "  (soft): Sequential(\n",
              "    (0): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "Model.load_state_dict(torch.load(cwd+'/../dicts/emotions_classifier_dict_LSTM', map_location=torch.device('cpu')))\n",
        "Model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0099,  0.0583, -0.1418,  ..., -0.0183, -0.0139,  0.0427],\n",
              "        [-0.0857,  0.0209, -0.0693,  ..., -0.0318, -0.0408,  0.1099],\n",
              "        [-0.1435, -0.0190,  0.3701,  ..., -0.0698, -0.0069, -0.1877],\n",
              "        ...,\n",
              "        [ 0.0467, -0.0495,  0.0721,  ..., -0.1968,  0.1171, -0.2641],\n",
              "        [ 0.4760, -0.0488,  0.1691,  ..., -0.1061, -0.1291, -0.3212],\n",
              "        [ 0.2292,  0.1495,  0.2034,  ..., -0.2226,  0.6667,  0.0490]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "e = next(Model.embedding[0].parameters())\n",
        "e.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1411, 280, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "X_test = np.dstack(dataset['documento_processado'].values).transpose(2,0,1)\n",
        "X_text = torch.FloatTensor(X_test)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'int' object is not callable",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-27-6abf8f17704f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\eduarda\\Documents\\Workspace\\project\\2020_INF425_NLP_SeReS\\eda\\funcs\\model_class.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     47\u001b[0m     '''Processamento realizado ao chamar y=modelo(x)\n\u001b[0;32m     48\u001b[0m     '''\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# aplica a etapa de embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# inverte dimensões (força \"batch first\" no hidden state)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mann\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;31m# passa o embedding médio pelas camadas da ANN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             \u001b[0mmax_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m             \u001b[0msorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
          ]
        }
      ],
      "source": [
        "preds = Model.forward(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset['documento_processado'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.forward(dataset['documento_processado'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset[\"previsoes\"] = [model.forward(x) for x in dataset['documento_processado']]\n",
        "dataset.head()"
      ]
    },
    {
      "source": [
        "## Preparando o input (Aka a nova distribuição média de emoções)\n",
        "\n",
        "Devemos pegar as softmax das emoções de vários tweets de um mesmo usuário e transformar em um só para o nosso modelo final"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hePZWJCqSkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c4de89-e60c-42e0-816d-370b8c3228be"
      },
      "source": [
        "idx2word = list(word2idx.keys()) # apenas transforma as chaves (palavras ordenadas) do dicionário word2idx em uma lista\n",
        "\n",
        "# testando a conversão \"index to word\":\n",
        "print(f'word for index 0:    {idx2word[0]}')\n",
        "print(f'word for index 100\": {idx2word[100]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqwc7jFLqUTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ec2bd1-0a0c-4dcb-b51c-c61a1443ba58"
      },
      "source": [
        "max_len = 30         # comprimento máximo da mensagem (em número de palavras)\n",
        "encoded_docs = []    # inicializa a lista de documentos codificados\n",
        "\n",
        "for doc in dataset['documento_processado']: # para cada texto\n",
        "  encoded_d = [word2idx.get(t,word2idx['<OOV>']) for t in doc]    # codifica o documento usando o dicionário word2idx\n",
        "  encoded_d += [word2idx['<PAD>']]*max(0, max_len-len(encoded_d))    # adiciona o padding, se necessário\n",
        "  \n",
        "  encoded_docs.append(encoded_d[:max_len])                           # trunca o documento e salva na lista de documentos codificados\n",
        "\n",
        "len(encoded_docs)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9kauNgMZB9i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "5b0967cc-6d83-4334-e4c9-a4525d095cfc"
      },
      "source": [
        "dataset['documento_processado'] = encoded_docs\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zW8Fg9Dqltf"
      },
      "source": [
        "#Chamando o modelo de previsão de emoções"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXqe73OzLzuB"
      },
      "source": [
        "import myclass\n",
        "from myclass import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUBVeYT_qXbK"
      },
      "source": [
        "model = torch.load('/content/drive/My Drive/Análise de Sentimentos/Projeto para 08-09/Models/newmodel.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "culebAKq-uCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4cfe2b0-69a0-4888-bf79-02e1da219ca5"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/My Drive/Análise de Sentimentos/Projeto para 08-09/Models/newmodel_dict'))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo6osPeIVMmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8f9b94-c203-4666-a112-e117a19c6851"
      },
      "source": [
        "e = next(model.embedding[0].parameters())\n",
        "e.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqwtEc3SYUn-"
      },
      "source": [
        "#Adcionando a *feature* do modelo de previsão de emoções"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlnNkA6XZXwZ"
      },
      "source": [
        "X_test = np.vstack(dataset['documento_processado'])\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NWNHn8ebrIm"
      },
      "source": [
        "preds = model.forward(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G9YYCSwN6X-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "01d6c568-7c6c-408f-a42a-f79963ae5adb"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6oSVpFP_1fs"
      },
      "source": [
        "## Criando colunas com os preds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWlMjKHG_38E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "4fa25704-bc6e-4ed9-ad69-6ce1b9ff81a5"
      },
      "source": [
        "dataset[\"previsoes\"] = [torch.exp(pred).detach().numpy() for pred in preds]\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXEBUcVYN-qV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "outputId": "628afb75-6bc0-450b-f383-87001f1541da"
      },
      "source": [
        "dataset.query(\"depressao==1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coIK0Y8xUmGi"
      },
      "source": [
        "# Tirando a média"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n__ap1jn6ng"
      },
      "source": [
        "df = dataset.copy()\n",
        "dataset.set_index('usuario', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWrwvJEdj-O3"
      },
      "source": [
        "#Funções necessárias\n",
        "\n",
        "def get_matriz_user(distributions):\n",
        "  \"\"\"\n",
        "  Pega as distruibuições do usuário (O resultado o modelo de emoções de todos os tweets) e cria uma matriz\n",
        "  \"\"\"\n",
        "  matriz = np.vstack(distributions)\n",
        "\n",
        "  return matriz\n",
        "\n",
        "\n",
        "def get_media_user(matriz):\n",
        "  \"\"\"\n",
        "  Pega a matriz dos vetores resultantes do modelo de previsão de emoções e faz a média\n",
        "  \"\"\"\n",
        "  media = matriz.mean(axis=0).reshape(1,-1)\n",
        "\n",
        "  return media"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpzvBEq5jKwk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "10a5d65a-68dd-4d52-b0bf-d2b685ac6dbc"
      },
      "source": [
        "unique_users1 = df.query('depressao == 1')['usuario'].unique()\n",
        "unique_users0 = df.query('depressao == 0')['usuario'].unique()\n",
        "\n",
        "df_final = pd.DataFrame(columns=['user','emotions_avg_dist', 'depression'])\n",
        "\n",
        "#EL GAMBIARRA (arrumar depois)\n",
        "  \n",
        "for user in unique_users1:\n",
        "  df_user = dataset.loc[user] #Pegando o usuário e seus tweets\n",
        "  distributions_of_user = df_user['previsoes'] #Pegando as distribuições\n",
        "\n",
        "  matriz_de_distribuicao = get_matriz_user(distributions_of_user)\n",
        "  media_usuario = get_media_user(matriz_de_distribuicao)\n",
        "  media_usuario = media_usuario/media_usuario.sum()\n",
        "\n",
        "  df_of_new_row = pd.DataFrame(data=[[user, media_usuario, 1]], columns=['user','emotions_avg_dist','depression']) #Criando uma nova linha\n",
        "  df_final = df_final.append(df_of_new_row,ignore_index=True) #Adcionando a nova linha no dataframe\n",
        "\n",
        "for user in unique_users0:\n",
        "  df_user = dataset.loc[user] #Pegando o usuário e seus tweets\n",
        "  distributions_of_user = df_user['previsoes'] #Pegando as distribuições\n",
        "\n",
        "  matriz_de_distribuicao = get_matriz_user(distributions_of_user)\n",
        "  media_usuario = get_media_user(matriz_de_distribuicao)\n",
        "  media_usuario = media_usuario/media_usuario.sum()\n",
        "\n",
        "  df_of_new_row = pd.DataFrame(data=[[user, media_usuario, 0]], columns=['user','emotions_avg_dist','depression']) #Criando uma nova linha\n",
        "  df_final = df_final.append(df_of_new_row,ignore_index=True) #Adcionando a nova linha no dataframe\n",
        "\n",
        "df_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi5_yiwey-_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a144bd2d-a5d5-412f-c67c-e587a85319d3"
      },
      "source": [
        "df_final.iloc[10]['emotions_avg_dist'].sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpQ4at9HOc2i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "b246a68e-6747-46b2-8a7a-c7f07502a0e5"
      },
      "source": [
        "df_final.query('depression==1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TZIQi8iAdOF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "dfab769b-0ea3-4a18-9e17-bb972336048a"
      },
      "source": [
        "df_final = df_final.sample(frac=1).reset_index(drop=True)\n",
        "df_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al4cDeNf4wWb"
      },
      "source": [
        "##Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxV7Xxtl5mb5"
      },
      "source": [
        "X = df_final.drop(['depression'], axis=1)\n",
        "y = df_final['depression']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPmwjP6m452Y"
      },
      "source": [
        "X_train_df, X_test_df, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=666, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgzSz03CfHwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c1b573-3e28-4449-f298-7b9dd68cb834"
      },
      "source": [
        "X_train_df.shape, y_train.shape, X_test_df.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QptYjCcjla8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00a1215-5ec7-4878-baef-cf78ec7519db"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1qgHfmnCj3q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f7f19b-1801-46db-fdd6-5b6f294224e1"
      },
      "source": [
        "y_train.value_counts(normalize=True) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_C-2IRFCt-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313f005a-2725-4387-b2e9-a25090632b3c"
      },
      "source": [
        "y_test.value_counts(normalize=True) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKX2uUE2lrEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32653345-512e-4de7-c0d5-7cdf41890eba"
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8IfyNkvFsin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "321d8c9c-b89e-49b4-f31f-05e1bd30a179"
      },
      "source": [
        "type(y_test.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XCwT_sSOAjW"
      },
      "source": [
        "## Criando ***El Modelo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymHu8xlPERUG"
      },
      "source": [
        "class depression_detection(nn.Module):\n",
        "  '''Modelo classificador de emoções\n",
        "  '''\n",
        "  # ----------------------------------------------#\n",
        "  # Método construtor\n",
        "  def __init__(self, n_in, num_layers, num_units): \n",
        "\n",
        "    super().__init__()  \n",
        "    ann_seq       = [] # \n",
        "\n",
        "    #--------------------------------------------------------------------------#\n",
        "    # ANN: Rede Neural Artifical Tradicional, com regressão logística na saída\n",
        "    for i in range(1, num_layers):\n",
        "      ann_seq.append(nn.Linear(in_features=num_units[i-1], out_features=num_units[i]))\n",
        "      ann_seq.append(nn.ReLU(inplace=True))\n",
        "    ann_seq.append(nn.Linear(in_features=num_units[-1], out_features=1))\n",
        "    ann_seq.append(nn.Sigmoid())\n",
        "    \n",
        "    #--------------------------------------------------------------------------#\n",
        "    # \"merge\" de todas as camamadas em uma layer sequencial \n",
        "    # (uma sequência para cada etapa)\n",
        "    self.ann= nn.Sequential(*ann_seq)           # etapa ANN\n",
        "    #--------------------------------------------------------------------------#\n",
        "\n",
        "  def forward(self, x): \n",
        "    '''\n",
        "    Processamento realizado ao chamar y=modelo(x)\n",
        "    '''\n",
        "    x = self.ann(x)        # passa o embedding médio pelas camadas da ANN\n",
        "    return x  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eratvuIJQVyG"
      },
      "source": [
        "def train_loop(model, data_train, data_test, max_epochs = 1000, print_iters = 5):\n",
        "  X_train, Y_train = data_train\n",
        "  X_test, Y_test = data_test\n",
        "  losses = []\n",
        "  accs = []\n",
        "  for i in range(max_epochs): # para cada época\n",
        "\n",
        "      #-----------------------------------#\n",
        "      # INÍCIO DO WORKFLOW DO TREINAMENTO #\n",
        "      # \n",
        "      # Add mistura\n",
        "      Y_pred = model.forward(X_train)         # apresente os dados de entrada para o modelo, e obtenha a previsão    \n",
        "      loss = criterion(Y_pred, Y_train)                      # calcule a perda (o custo, o erro)\n",
        "      optimizer.zero_grad()                   # inicialize os gradientes\n",
        "      loss.backward()                         # backpropagation sobre a perda atual (cálculo dos novos gradientes) \n",
        "      optimizer.step()                        # atualização dos parâmetros da rede utilizando a regra do otimizador escolhido\n",
        "\n",
        "      \n",
        "      # FIM DO WORKFLOW DO TREINAMENTO    #\n",
        "      #-----------------------------------#\n",
        "\n",
        "      # ------ Bloco Opcional ------ #\n",
        "      # Salvando métricas\n",
        "      losses.append(loss)                     # salvando a perda atual\n",
        "      acc = calc_accuracy(Y_pred, Y_train)     # calcula a taxa de acerto atual\n",
        "      accs.append(acc)\n",
        "      \n",
        "      # Imprimindo resultados parciais\n",
        "      if i % print_iters ==0: # a cada 10 iterações\n",
        "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}') \n",
        "      #-----------------------------------#\n",
        "\n",
        "  #----------------------------------------------------------------------------# \n",
        "  print('\\n# Finished training!')\n",
        "  print(f'# --> epoch: {i}  \\n# --> initial loss: {losses[0]:10.8f} ,  \\n# --> accuracy: {acc:2.8f} , \\n# --> final loss: {losses[-1]:10.8f}')\n",
        "  \n",
        "  # retornando resultados\n",
        "  return model, losses, accs\n",
        "\n",
        "# Redefinindo cálculo da taxa de acerto \n",
        "def calc_accuracy(y_pred, y_true):\n",
        "  ''' Helper function para calcular a taxa de acerto deste exemplo.\n",
        "  '''\n",
        "  num_hits  = torch.sum(torch.round(y_pred)==y_true).numpy()\n",
        "  num_total =  float(y_true.numel())\n",
        "  acc=  num_hits/num_total\n",
        "  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_PCcktAFwm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f96eec9-d022-46f6-f942-dfeb2b009e9e"
      },
      "source": [
        "\n",
        "X_train = np.vstack(X_train_df['emotions_avg_dist'])\n",
        "Y_train = np.vstack(y_train).reshape(-1,1)\n",
        "X_train.shape, X_train[0].shape, Y_train.shape, Y_train[0].shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj_U85B9OxwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a763cca6-c180-47b4-e3cc-039e3673fbf5"
      },
      "source": [
        "X_test = np.vstack(X_test_df['emotions_avg_dist'])\n",
        "Y_test = np.vstack(y_test).reshape(-1,1)\n",
        "X_test.shape, X_test[0].shape, Y_test.shape, Y_test[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sesjq2jHLFd6"
      },
      "source": [
        "data_train = (torch.FloatTensor(X_train), torch.FloatTensor(Y_train))\n",
        "\n",
        "data_test = (torch.FloatTensor(X_test), torch.FloatTensor(Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De4DmcsBzEqV"
      },
      "source": [
        "## Melhorando com hiperparâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb9XeTW1zKME"
      },
      "source": [
        "# Código baseado no github do professor Bruno Fontana. \n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "Ajustar_Hiperparametros = True     \n",
        "\n",
        "param_dict = {}\n",
        "param_dict['learning_rate'] = np.linspace(0.01, 0.1, 10) # [0.1, 0.01, 0.001] # exemplos de buscas: np.linspace(1e-2,5e-2,5) ou np.logspace(-3,-1,20)\n",
        "param_dict['layers'] = [\n",
        "                        (2, [6, 40]),\n",
        "                        (2, [6, 48]),\n",
        "                        (2, [6, 52]),\n",
        "                        (3, [6, 48, 8]),\n",
        "                        (3, [6, 48, 16]),\n",
        "                        (3, [6, 48, 32]),\n",
        "                        (3, [6, 48, 48]),\n",
        "                        (3, [6, 48, 64])]\n",
        "                        # (4, [6, 100, 50, 25]), \n",
        "                        # (5, [6, 200, 100, 50, 25]),\n",
        "                        # (6, [6, 400, 200, 100, 50, 25])]              # exemplos de buscas: np.arange(start=1,stop=4)\n",
        "# param_dict['num_units'] = [[6, 100, 50, 25], [6, 200, 100, 50, 25]]         # exemplos de buscas: np.arange(10,15)\n",
        "\n",
        "param_dict['max_epochs']= [3000]     # maximum number of iterations running over the training set\n",
        "\n",
        "Num_HyperParams_to_test = len(ParameterGrid(param_dict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlKqhXmycVlf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d9ba723-5438-420e-da83-736aabad6358"
      },
      "source": [
        "criterion = nn.BCELoss() # binary cross-entropy\n",
        "\n",
        "if Ajustar_Hiperparametros:\n",
        "  acc_test_list = []\n",
        "  max_acc_test = -np.inf\n",
        "  best_params = None\n",
        "  idx_best = None\n",
        "  for idx, params in enumerate(ParameterGrid(param_dict)):\n",
        "    learning_rate = params['learning_rate']      # learning rate for parameter updates\n",
        "    L, num_units = params['layers']                              # depth of ANN (number of hidden layers)\n",
        "    #num_units = params['num_units']                    # 2**Nu_exp = Number of units per HL\n",
        "    max_epochs = params['max_epochs']            # num. of iterations over the full dataset\n",
        "\n",
        "    print(f'Testing parameters {idx}/{Num_HyperParams_to_test}: {params}')\n",
        "\n",
        "    torch.manual_seed(666)\n",
        "    model = depression_detection(n_in=6, num_layers=L, num_units=num_units)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) \n",
        "    model, losses, accs = train_loop(model, data_train, data_test, max_epochs=max_epochs, print_iters=1000)\n",
        "\n",
        "    # print(f'Model {model}',f'Criterion: {criterion}',f'Optimizer: {optimizer}',sep=2*'\\n')\n",
        "\n",
        "    X_test, Y_test = data_test\n",
        "    with torch.no_grad():\n",
        "      Y_pred = model(X_test)\n",
        "      num_hits  = torch.sum(torch.round(Y_pred)==Y_test).numpy()\n",
        "      num_total =  float(Y_test.numel())\n",
        "      acc_test = num_hits/num_total\n",
        "      # print(f'TEST SCORE: Torch loss {acc_test.item():10.6f}  (ANN)')\n",
        "\n",
        "    if acc_test > max_acc_test:\n",
        "      max_acc_test = acc_test\n",
        "      best_params = params\n",
        "      losses_best, acc_best = (losses, accs)\n",
        "      idx_best = idx\n",
        "      best_model = model\n",
        "\n",
        "    acc_test_list.append(acc_test)\n",
        "\n",
        "\n",
        "    # clear_output(wait=True)\n",
        "  print(\"best_params\", best_params, \"acc_test_list\", acc_test_list, \"idx_best\", idx_best, \"acc_best\", acc_test_list[idx_best], sep=\"\\n\")\n",
        "\n",
        "else:\n",
        "  model = depression_detection(n_in=6, num_layers=2, num_units=[6,48])\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = 0.1) \n",
        "  best_model, losses_best, acc_best = train_loop(model, data_train, data_test,max_epochs=2000, print_iters=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FX94z1Us1SS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c589b63-ef08-4015-e21b-8484535c595f"
      },
      "source": [
        "print(best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR7Y90AYF3MH"
      },
      "source": [
        "# Model, losses, accs = train_loop(model, data_train, data_test, max_epochs=1000, print_iters=1) # note que o modelo é sobrescrito pela saída treinada"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTGzXljDJIf8"
      },
      "source": [
        "X_train = torch.FloatTensor(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWfkyWf5Io8_"
      },
      "source": [
        "Y_pred = best_model(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnMGabph0Gld"
      },
      "source": [
        "#Visualizando resultados\n",
        "\n",
        "##Gráfico de Loss e Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxVYd6b3a7V3"
      },
      "source": [
        "def plot_loss_and_accuracy(losses, accs):\n",
        "\n",
        "  fig, ax_tuple = plt.subplots(1, 2, figsize=(16,6))\n",
        "  fig.suptitle('Loss and accuracy')\n",
        "\n",
        "  for i, (y_label, y_values) in enumerate(zip(['BCE loss','Accuracy'],[losses, accs])):\n",
        "    ax_tuple[i].plot(range(len(y_values)),  y_values, label='train')\n",
        "    ax_tuple[i].set_xlabel('epochs')\n",
        "    ax_tuple[i].set_ylabel(y_label)\n",
        "    ax_tuple[i].legend()\n",
        "  \n",
        "  ax_tuple[1].set_ylim([0,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwtZIfFHc8wX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "92b38b95-9555-4ca8-b1a1-635cd158b74e"
      },
      "source": [
        "plot_loss_and_accuracy(losses_best, acc_best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWb_i2uv0Ofg"
      },
      "source": [
        "##Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwy__62BvX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57ae0f9-7745-450e-b6f9-c608e35fe75d"
      },
      "source": [
        "X_test = np.vstack(X_test)\n",
        "Y_test = np.vstack(y_test).reshape(-1,1)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "Y_test =  torch.FloatTensor(Y_test)\n",
        "X_test.shape, Y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RLiVrWaBayt"
      },
      "source": [
        "Y_pred = best_model(X_test)\n",
        "#Y_pred[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_KwdHhcUAX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e769448-715c-4172-9e15-8d7625367664"
      },
      "source": [
        "Y_test.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZjzTNe6oBG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852c8e10-cde6-4ccb-9529-8c52d0676028"
      },
      "source": [
        "X, Y = data_test\n",
        "with torch.no_grad():\n",
        "    Y2 = best_model(X)\n",
        "    num_hits  = torch.sum(torch.round(Y2)==Y).numpy()\n",
        "    num_total =  float(Y.numel())\n",
        "    acc_test = num_hits/num_total\n",
        "\n",
        "acc_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQmeIj_Lc9hv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "e93a2a27-9a50-4256-dfcc-462711e9d1ad"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "\n",
        "# confusion matrix daora TEM Q MELHORAR\n",
        "def plot_conf_mat(y_test, y_preds, norm=None):\n",
        "   fig, ax = plt.subplots(figsize=(8, 6))\n",
        "   ax = sns.heatmap(confusion_matrix(y_test, y_preds, normalize=norm),\n",
        "                   annot=True,\n",
        "                    fmt=\"d\",\n",
        "                    cmap=\"YlOrRd\")\n",
        "   plt.xlabel(\"Resultado previsto\")\n",
        "   plt.ylabel(\"Resultado real\")\n",
        "\n",
        "\n",
        "plot_conf_mat(Y_test.detach().numpy(), Y_pred.detach().numpy().round())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNIGo_L_QP4X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "dbff1923-4120-4685-b2df-70f4b415f361"
      },
      "source": [
        "Y_predtrain = best_model(X_train)\n",
        "plot_conf_mat(Y_train, Y_predtrain.detach().numpy().round())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYY_mw6eV65_"
      },
      "source": [
        "## F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPLwDoDdB32h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec55799c-037d-47d5-f33d-f5ea07f98138"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(Y_test.detach().numpy(), Y_pred.detach().numpy().round())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJW2zA8mWniX"
      },
      "source": [
        "## Recall Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVOHzdViWWjP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51eee87c-6a81-45d1-d0d3-369b3e17ae0e"
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "recall_score(Y_test.detach().numpy(), Y_pred.detach().numpy().round())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zuoy_Rp6Gvzy"
      },
      "source": [
        "##Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbTboqG4GqJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81086c80-ea2a-4ce5-d237-16e975c218c6"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision_score(Y_test.detach().numpy(), Y_pred.detach().numpy().round())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ9b9nJtXQkS"
      },
      "source": [
        "## ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxVthM5PYICd"
      },
      "source": [
        "# função pra plotar a ROC curve\n",
        "\n",
        "def plot_roc_curve(fpr, tpr):\n",
        "    \n",
        "    plt.plot(fpr, tpr, color=\"orange\", label=\"ROC\")  \n",
        "    plt.plot([0,1],[0,1], color=\"darkblue\", linestyle=\"--\", label=\"Guessing\")\n",
        "    \n",
        "    plt.xlabel(\"Taxa de falsos positivos  (fpr)\")\n",
        "    plt.ylabel(\"Taxa verdadeira positiva (tpr)\")\n",
        "    plt.title(\"Receiver Operating Characteristics (ROC) curve\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOpJwMuHW3vx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "d76b35f3-346d-4428-a1cc-094958d92da0"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(Y_test.detach().numpy(), Y_pred.detach().numpy())\n",
        "plot_roc_curve(fpr, tpr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdVp97y3ZCHs"
      },
      "source": [
        "## ROC/AUC Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHknSm20XcCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "412e9b02-0680-4ba9-b18b-4b1be60cbc68"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(Y_test.detach().numpy(), Y_pred.detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBfMmQW3Z3wc"
      },
      "source": [
        "## Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkY7tW2qZJ24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5da52236-aa0f-48ee-a358-bea72d1ecccd"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# compare the truth labels to the predicted labels\n",
        "print(classification_report(Y_test.detach().numpy(), Y_pred.detach().numpy().round()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNZg8ZXhQK__"
      },
      "source": [
        "##Falsos Negativos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANqqz92QzZSB"
      },
      "source": [
        "moods = {\"Anger\": 0, \"Fear\" : 1, \"Joy\" : 2, \"Love\" : 3, \"Sadness\" : 4, \"Suprise\" : 5}\n",
        "sdoom = {0 : \"Anger\", 1: \"Fear\", 2: \"Joy\", 3: \"Love\", 4: \"Sadness\", 5: \"Suprise\"}\n",
        "emotions = list(moods.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neYqSF6Ruzq_"
      },
      "source": [
        "Ytrue1 = Y_test.detach().numpy() == 1\n",
        "Ypred0 = Y_pred.detach().numpy().round() == 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cDbTP4u0_Ur",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "48af1c1b-5f79-47c6-f0c9-d3d86a63bb02"
      },
      "source": [
        "X_test_df[Ytrue1.reshape(-1) & Ypred0.reshape(-1)]  #Onde era verdadeiro e foi previsto falso  (FALSO NEGATIVO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZmmM0vmSO-d"
      },
      "source": [
        "Primeiro exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Anv7P0f6ywSk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "349454b5-2c4c-4fb2-8624-15583d856ff4"
      },
      "source": [
        "usuario_teste = 'je_ecobaby'\n",
        "dataset.loc[usuario_teste][['texto', 'depressao','previsoes']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjeEU-QBQc5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba05b404-06cc-4c6e-d1d2-301ee5195252"
      },
      "source": [
        "dataset.loc[usuario_teste]['previsoes'].apply(lambda x: sdoom[np.argmax(np.array(x))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JsJVSXc75dL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "9d119799-1367-42ec-f47f-1682b7e680c9"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "jairo = dataset.set_index('user').loc[usuario_teste][0]\n",
        "jairo = jairo.reshape(-1)\n",
        "plt.bar(emotions, jairo, color=['lightcoral', 'khaki', 'bisque', 'lightsteelblue', 'lightgreen', 'thistle'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwcke9HW1tY-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "479b416b-a628-4062-a57d-fbfe6a8d0e9b"
      },
      "source": [
        "jairo = X_test_df.set_index('user').loc[usuario_teste][0]\n",
        "jairo = jairo.reshape(-1)\n",
        "sns.barplot(y=jairo,x=emotions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnutD6HhRF6R"
      },
      "source": [
        "##Falsos Positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCneO4mPRVKN"
      },
      "source": [
        "Ytrue0 = Y_test.detach().numpy() == 0\n",
        "Ypred1 = Y_pred.detach().numpy().round() == 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC7X33NfRcy4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "eb6992f2-1e85-44ab-c5e4-92d5d55dddcf"
      },
      "source": [
        "X_test_df[Ytrue0.reshape(-1) & Ypred1.reshape(-1)]  #Onde era falso e foi previsto verdadeiro  (FALSO POSITIVE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrYun7X4USRE"
      },
      "source": [
        "Primeiro exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okq9GLBsUQ_b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d141be00-7517-4cc7-eeb3-ea9cd5fb0c3d"
      },
      "source": [
        "usuario_teste = 'litarib'\n",
        "dataset.loc[usuario_teste][['texto', 'depressao','previsoes']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxiUUFEeUXCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f463a4-8d55-4645-f8ee-428719d03a43"
      },
      "source": [
        "dataset.loc[usuario_teste]['previsoes'].apply(lambda x: sdoom[np.argmax(np.array(x))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK-mZC8C_rfE"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "jairo = X_test_df.set_index('user').loc[usuario_teste][0]\n",
        "jairo = jairo.reshape(-1)\n",
        "plt.bar(emotions, jairo, color=['lightcoral', 'khaki', 'bisque', 'lightsteelblue', 'lightgreen', 'thistle'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6GbNmVbUak4"
      },
      "source": [
        "jairo = X_test_df.set_index('user').loc[usuario_teste][0]\n",
        "jairo = jairo.reshape(-1)\n",
        "sns.barplot(y=jairo,x=emotions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbjXV7n5RJTX"
      },
      "source": [
        "##True Positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrWKrg_h3odW"
      },
      "source": [
        "Ytrue1 = Y_test.detach().numpy() == 1\n",
        "Ypred1 = Y_pred.detach().numpy().round() == 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cjBmizA6I8V"
      },
      "source": [
        "X_test_df[Ytrue1.reshape(-1) & Ypred1.reshape(-1)]  #Onde era verdadeiro e foi previsto verdadeiro  (True positive)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYqJJTJR6h5p"
      },
      "source": [
        "usuario_teste = 'ggukpersona'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iofllRO86T-M"
      },
      "source": [
        "dataset.loc[usuario_teste][['texto', 'depressao','previsoes']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnXu57d_6af6"
      },
      "source": [
        "dataset.loc[usuario_teste]['previsoes'].apply(lambda x: sdoom[np.argmax(np.array(x))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giNigeXg_y5k"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "jairo = X_test_df.set_index('user').loc[usuario_teste][0]\n",
        "jairo = jairo.reshape(-1)\n",
        "plt.bar(emotions, jairo, color=['lightcoral', 'khaki', 'bisque', 'lightsteelblue', 'lightgreen', 'thistle'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbHnCvzY6d7D"
      },
      "source": [
        "jairo = X_test_df.set_index('user').loc[usuario_teste][0]\n",
        "jairo = jairo.reshape(-1)\n",
        "sns.barplot(y=jairo,x=emotions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHVXu3rlXQg4"
      },
      "source": [
        "Segundo exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loA2wjWn6re4"
      },
      "source": [
        "usuario_teste = 'barbaraton'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwMo6v7dXcmv"
      },
      "source": [
        "dataset.loc[usuario_teste][['texto', 'depressao','previsoes']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cCh4BgRXgHk"
      },
      "source": [
        "dataset.loc[usuario_teste]['previsoes'].apply(lambda x: sdoom[np.argmax(np.array(x))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVBTVgZ__1E2"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "jairo = X_test_df.set_index('user').loc[usuario_teste][0]\n",
        "jairo = jairo.reshape(-1)\n",
        "plt.bar(emotions, jairo, color=['lightcoral', 'khaki', 'bisque', 'lightsteelblue', 'lightgreen', 'thistle'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgYmQcF_Xk6k"
      },
      "source": [
        "jairo = X_test_df.set_index('user').loc[usuario_teste][0]\n",
        "jairo = jairo.reshape(-1)\n",
        "sns.barplot(y=jairo,x=emotions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUu5uITnXsZ7"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}